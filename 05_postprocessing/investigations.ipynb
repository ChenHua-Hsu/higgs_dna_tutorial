{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import hist\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMS style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep as hep\n",
    "\n",
    "hep.style.use(\"CMS\")\n",
    "palette = [\"#5790fc\", \"#f89c20\", \"#e42536\", \"#964a8b\", \"#9c9ca1\", \"#7a21dd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input\n",
    "Now that we've produced all our `.parquet` and `.root` trees we can check that everything is in order, again with `awkward` and `numpy`.\n",
    "\n",
    "First we load the MC and data samples as we did in the previous steps, starting from the merged `.parquets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MC samples\n",
    "MC = {}\n",
    "processes = [\"ggh_M-120\", \"ggh_M-125\", \"ggh_M-130\", \"vbf_M-120\", \"vbf_M-125\", \"vbf_M-130\"]\n",
    "for i, proc in enumerate(processes):\n",
    "    MC[f'{proc}'] = {}\n",
    "    MC[f'{proc}'][\"untagged\"] = ak.from_parquet(f'05_NTuples/merged_untagged/{proc}_preEE/NOTAG_merged.parquet')\n",
    "    for cat in [\"EBEB_highR9highR9\", \"EBEB_highR9lowR9\", \"EBEB_lowR9highR9\"]:\n",
    "        MC[f'{proc}'][cat] = ak.from_parquet(f'05_NTuples/merged/{proc}_preEE/nominal/{cat}_merged.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the weights\n",
    "\n",
    "In the trees there are multiple fields that store different version of the event weights. Let's start having a look at what's available in one of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available weight fields:\")\n",
    "for f in MC[proc][\"EBEB_highR9highR9\"].fields:\n",
    "    if \"weight\" in f:\n",
    "        print(f\"    {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here you can see that all the weight systematics variuations are stored in different branches. Furthermore there are different versions of the nominal weigh:\n",
    "* `weight`: weight of the events with corrections applied, after the normalisation to Efficiency x Acceptance made during the merging step.\n",
    "* `weight_nominal`: same as the previous field but before the normalisation with respect to the sum of the Generator weight of the full MC sample.\n",
    "* `weight_central`: set of weights centered around one, this is needed to plot sistematic variations properly and not consider corrections twice.\n",
    "\n",
    "Now we can have a look at the expected number of events for each sample according to theoretical values of cross section and branching fractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_section = {\n",
    "    \"ggh_M-120\" : 56110,   # from https://arxiv.org/pdf/2402.09955\n",
    "    \"ggh_M-125\" : 52230,\n",
    "    \"ggh_M-130\" : 48750,\n",
    "    \"vbf_M-120\" : 4078,  # theoretical cross sections are not available for mass values different from 125 for VBF\n",
    "    \"vbf_M-125\" : 4078,\n",
    "    \"vbf_M-130\" : 4078,\n",
    "}\n",
    "eff = {}\n",
    "\n",
    "lumi = 8.\n",
    "BF = 0.00227\n",
    "\n",
    "print(\"Expected Run 3 preEE events:\")\n",
    "print(f\"  luminosity: {lumi} /fb\")\n",
    "print(f'  H â†’ \\u03b3 \\u03b3 BR: {BF}')\n",
    "for sample in cross_section:\n",
    "    eff[sample] = ak.sum(MC[sample][\"untagged\"].weight)\n",
    "    print(f\"    {sample}:\")\n",
    "    print(f\"        * produced events: {cross_section[sample] * lumi * BF}\")\n",
    "    print(f\"        * expected selected events: {cross_section[sample] * lumi * BF * eff[sample]}\")\n",
    "    print(f\"        * efficiency x acceptance: {eff[sample]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And have a look at the structure and sum of the different weight fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sum of weight_central:', ak.sum(MC[proc][\"untagged\"].weight_central), MC[proc][\"untagged\"].weight_central[:5].tolist())\n",
    "print('sum of weight:', ak.sum(MC[proc][\"untagged\"].weight), MC[proc][\"untagged\"].weight[:5].tolist())\n",
    "print('sum of weight_nominal:', ak.sum(MC[proc][\"untagged\"].weight_nominal), MC[proc][\"untagged\"].weight_nominal[:5].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot systematics an mass variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for output plots\n",
    "plots_dir = './plots'\n",
    "Path(plots_dir).mkdir(exist_ok=True)\n",
    "\n",
    "# Define the binning\n",
    "n_bins = 120\n",
    "x_low = 90\n",
    "x_high = 150\n",
    "binning = np.linspace(x_low, x_high, n_bins + 1)\n",
    "width = binning[1] - binning[0]\n",
    "center = (binning[:-1] + binning[1:]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass plot\n",
    "\n",
    "We then create a mass histograms starting from our data and MC arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1,1, figsize=(7, 7))\n",
    "\n",
    "var = \"mass\"\n",
    "\n",
    "LeadPhoton_et_ax  = hist.axis.Regular(n_bins, x_low, x_high, flow=False, name=\"ax\")\n",
    "LeadPhoton_et_cax_ggh = hist.axis.StrCategory([label for label in processes if \"ggh\" in label], name=\"c\")\n",
    "LeadPhoton_et_cax_vbf = hist.axis.StrCategory([label for label in processes if \"vbf\" in label], name=\"c\")\n",
    "\n",
    "full_hist_ggh = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_ggh)\n",
    "full_hist_ggh_err = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_ggh)\n",
    "full_hist_vbf = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_vbf)\n",
    "full_hist_vbf_err = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_vbf)\n",
    "\n",
    "for sample in [*MC]:\n",
    "    for cat in MC[sample]:\n",
    "        MC[sample][cat][\"weight_norm\"] = MC[sample][cat][\"weight\"] * cross_section[sample] * lumi * BF\n",
    "        MC[sample][cat][\"square_weight\"] = MC[sample][cat][\"weight_norm\"] ** 2\n",
    "\n",
    "        if cat == \"EBEB_highR9highR9\":\n",
    "            if \"ggh\" in sample:\n",
    "                full_hist_ggh.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"weight_norm\"], c=sample)\n",
    "                full_hist_ggh_err.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"square_weight\"], c=sample)\n",
    "            elif \"vbf\" in sample:\n",
    "                full_hist_vbf.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"weight_norm\"], c=sample)\n",
    "                full_hist_vbf_err.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"square_weight\"], c=sample)\n",
    "\n",
    "ggh_stack = full_hist_ggh.stack(\"c\")\n",
    "ggh_stack_err = full_hist_ggh_err.stack(\"c\")\n",
    "\n",
    "stack = False\n",
    "ggh_stack[::-1].plot(ax=ax0, stack=stack, histtype=\"step\")\n",
    "\n",
    "mc = {}\n",
    "mc[\"bins\"] = {}\n",
    "mc[\"errs\"] = {}\n",
    "mc[\"edges\"] = {}\n",
    "\n",
    "# this is useful to manipulate bin content better when doing ratios and error plotting\n",
    "for sample in [*full_hist_ggh.axes[1]]:\n",
    "    mc[\"bins\"][sample], mc[\"edges\"][sample] = full_hist_ggh[:,sample].to_numpy()\n",
    "    half_bin = np.abs((mc[\"edges\"][sample][1] - mc[\"edges\"][sample][0])) / 2\n",
    "    mc[\"edges\"][sample] = mc[\"edges\"][sample] + half_bin\n",
    "    mc[\"errs\"][sample] = np.sqrt(full_hist_ggh[:,sample].to_numpy()[0])\n",
    "\n",
    "ydn = {}\n",
    "yup = {}\n",
    "#create up and down edges to plot shaded area for each bin\n",
    "for sample in [*full_hist_ggh.axes[1]]:\n",
    "    ydn[sample] = [mc[\"bins\"][sample][i] - x for i, x in enumerate(mc[\"errs\"][sample])]\n",
    "    yup[sample] = [mc[\"bins\"][sample][i] + x for i, x in enumerate(mc[\"errs\"][sample])]\n",
    "\n",
    "# plot shaded area for MC errors\n",
    "for j, sample in enumerate([*full_hist_ggh.axes[1]]):\n",
    "    if stack: break\n",
    "    for i, x in enumerate(mc[\"edges\"][sample][:-1]):\n",
    "        if i == 0:\n",
    "            ax0.fill_between([x - half_bin, x + half_bin], [ydn[sample][i], ydn[sample][i]], [yup[sample][i], yup[sample][i]], facecolor=palette[2::-1][j], alpha=0.5, edgecolor=palette[2::-1][j], label=f\"{sample} stat unc.\") # we want just one entry in the legend\n",
    "        else:\n",
    "            ax0.fill_between([x - half_bin, x + half_bin], [ydn[sample][i], ydn[sample][i]], [yup[sample][i], yup[sample][i]], facecolor=palette[2::-1][j], alpha=0.5, edgecolor=palette[2::-1][j], label=\"\")\n",
    "\n",
    "# cosmetics\n",
    "ax0.set_ylabel('Events', fontsize=14)\n",
    "ax0.set_xlabel('', fontsize=1)\n",
    "ax0.set_title(r'$ggH \\;\\rightarrow \\gamma\\gamma$ Mass', fontsize=14)\n",
    "ax0.tick_params(axis='x', labelsize=10)\n",
    "ax0.tick_params(axis='y', labelsize=10)\n",
    "ax0.grid(color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Style\n",
    "handles, labels = ax0.get_legend_handles_labels()\n",
    "ax0.legend(handles[::-1], labels[::-1], prop={'size': 14})\n",
    "#hep.cms.label()\n",
    "\n",
    "ax0.set_xlim([x_low, x_high])\n",
    "ax0.set_xlabel('Mass [GeV]', fontsize=14)\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.plot()\n",
    "plt.show()\n",
    "plt.savefig(f'{plots_dir}/ggh_masses.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight systematic \n",
    "\n",
    "We can now have a look at the effect of the weight systematics, we plot the Photon ID one, what is the effect of this systematic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1,1, figsize=(7, 7))\n",
    "\n",
    "var = \"mass\"\n",
    "n_bins = 30\n",
    "\n",
    "LeadPhoton_et_ax  = hist.axis.Regular(n_bins, x_low, x_high, flow=False, name=\"ax\")\n",
    "LeadPhoton_et_cax_ggh = hist.axis.StrCategory([\"nominal\", \"PhotonID_Up\", \"PhotonID_Down\"], name=\"c\")\n",
    "\n",
    "full_hist_ggh = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_ggh)\n",
    "\n",
    "sample = \"ggh_M-125\"\n",
    "cat == \"EBEB_highR9highR9\"\n",
    "full_hist_ggh.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"weight_central\"], c=\"nominal\")\n",
    "full_hist_ggh.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"weight_SF_photon_IDUp\"], c=\"PhotonID_Up\")\n",
    "full_hist_ggh.fill(ax = MC[sample][cat][var], weight = MC[sample][cat][\"weight_SF_photon_IDDown\"], c=\"PhotonID_Down\")\n",
    "\n",
    "ggh_stack = full_hist_ggh.stack(\"c\")\n",
    "\n",
    "stack = False\n",
    "ggh_stack[::-1].plot(ax=ax0, stack=stack, histtype=\"step\")\n",
    "\n",
    "# cosmetics\n",
    "ax0.set_ylabel('A.U.', fontsize=14)\n",
    "ax0.set_xlabel('', fontsize=1)\n",
    "ax0.set_title(r'$ggH \\;\\rightarrow \\gamma\\gamma$ Mass - effect of weight systematics', fontsize=14)\n",
    "ax0.tick_params(axis='x', labelsize=10)\n",
    "ax0.tick_params(axis='y', labelsize=10)\n",
    "ax0.grid(color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Style\n",
    "handles, labels = ax0.get_legend_handles_labels()\n",
    "ax0.legend(handles[::-1], labels[::-1], prop={'size': 14})\n",
    "# hep.cms.label()\n",
    "\n",
    "ax0.set_xlim([x_low, x_high])\n",
    "ax0.set_xlabel('Mass [GeV]', fontsize=14)\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.plot()\n",
    "plt.show()\n",
    "plt.savefig(f'{plots_dir}/ggh_weight_syst.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object systematic\n",
    "\n",
    "Let's look at object systematics now, to do so we have to load the variated events from different `.parquet`. What is the difference between the effect of the Scale systematic and the Photon Id one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MC samples\n",
    "MC_variations = {}\n",
    "proc = \"ggh_M-120\"\n",
    "for var in [\"nominal\", \"Scale_up\", \"Scale_down\", \"Smearing_up\", \"Smearing_down\"]:\n",
    "    MC_variations[f'{var}'] = {}\n",
    "    for cat in [\"EBEB_highR9highR9\", \"EBEB_highR9lowR9\", \"EBEB_lowR9highR9\"]:\n",
    "        MC_variations[f'{var}'][cat] = ak.from_parquet(f'05_NTuples/merged/{proc}_preEE/{var}/{cat}_merged.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax0 = plt.subplots(1,1, figsize=(7, 7))\n",
    "\n",
    "var = \"mass\"\n",
    "n_bins = 30\n",
    "LeadPhoton_et_ax  = hist.axis.Regular(n_bins, x_low, x_high, flow=False, name=\"ax\")\n",
    "LeadPhoton_et_cax_ggh = hist.axis.StrCategory([\"nominal\", \"Scale_up\", \"Scale_down\"], name=\"c\")\n",
    "\n",
    "full_hist_ggh = hist.Hist(LeadPhoton_et_ax, LeadPhoton_et_cax_ggh)\n",
    "\n",
    "cat == \"best\"\n",
    "for variation in [\"nominal\", \"Scale_up\", \"Scale_down\"]:\n",
    "    full_hist_ggh.fill(ax = MC_variations[variation][cat][var], weight = MC_variations[variation][cat][\"weight\"], c=variation)\n",
    "\n",
    "ggh_stack = full_hist_ggh.stack(\"c\")\n",
    "\n",
    "stack = False\n",
    "ggh_stack[::-1].plot(ax=ax0, stack=stack, histtype=\"step\")\n",
    "\n",
    "# cosmetics\n",
    "ax0.set_ylabel('Eff x Acc', fontsize=14)\n",
    "ax0.set_xlabel('', fontsize=1)\n",
    "ax0.set_title(r'$ggH \\;\\rightarrow \\gamma\\gamma$ Mass - effect of Scale systematic', fontsize=14)\n",
    "ax0.tick_params(axis='x', labelsize=10)\n",
    "ax0.tick_params(axis='y', labelsize=10)\n",
    "ax0.grid(color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Style\n",
    "handles, labels = ax0.get_legend_handles_labels()\n",
    "ax0.legend(handles[::-1], labels[::-1], prop={'size': 14})\n",
    "# hep.cms.label()\n",
    "\n",
    "ax0.set_xlim([x_low, x_high])\n",
    "ax0.set_xlabel('Mass [GeV]', fontsize=14)\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.plot()\n",
    "plt.show()\n",
    "plt.savefig(f'{plots_dir}/ggh_object_sys.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROOT trees\n",
    "\n",
    "Now we can also check the ROOT version of the same quantities by looking at the files obtaine after the `--root` step of the postprocessing.\n",
    "\n",
    "We start loading the files with `uproot`. From the structure of the directory in the root file you can see that in this case all the variation and categories are included in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = uproot.open('05_NTuples/root/ggh_M-125_preEE/output_GluGluHToGG_M125_13TeV_amcatnloFXFX_pythia8.root')\n",
    "\n",
    "file.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at what is inside one of the category `TBranch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = file['DiphotonTree/ggh_125_13TeV_EBEB_highR9highR9']\n",
    "ggh_125_EBEB = tree.arrays()\n",
    "ggh_125_EBEB.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on!\n",
    "Now Try to plot something from the ROOT files and check that the expected number of events has not changed after the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
